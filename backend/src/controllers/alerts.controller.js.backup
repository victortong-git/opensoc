const { models, sequelize } = require('../database/models');
const { asyncHandler, NotFoundError, ValidationError } = require('../middleware/error.middleware');
const embeddingHelper = require('../services/embeddingHelper');
const { Op } = require('sequelize');
const aiGenerationService = require('../services/aiGenerationService');
const alertAnalysisService = require('../services/alertAnalysisService');
const notificationService = require('../services/notificationService');
const aiAgentLogService = require('../services/aiAgentLogService');
const alertStatsService = require('../services/alertStatsService');
const alertAnalysisHelper = require('./helpers/alertAnalysisHelper');
const alertClassificationHelper = require('./helpers/alertClassificationHelper');
const incidentFormGenerationService = require('../services/incidentFormGenerationService');

/**
 * Get all alerts with filtering and pagination
 * GET /api/alerts
 */
const getAlerts = asyncHandler(async (req, res) => {
  const organizationId = req.user.organizationId;
  const {
    page = 1,
    limit = 20,
    sortBy = 'createdAt',
    sortOrder = 'desc',
    severity,
    status,
    sourceSystem,
    assetId,
    startDate,
    endDate,
    search,
  } = req.query;

  // Build where clause
  const where = { organizationId };

  // Apply filters
  if (severity) {
    const severityArray = Array.isArray(severity) ? severity : [severity];
    where.severity = { [Op.in]: severityArray.map(s => parseInt(s)) };
  }

  if (status) {
    const statusArray = Array.isArray(status) ? status : [status];
    where.status = { [Op.in]: statusArray };
  }

  if (sourceSystem) {
    const sourceSystemArray = Array.isArray(sourceSystem) ? sourceSystem : [sourceSystem];
    where.sourceSystem = { [Op.in]: sourceSystemArray };
  }

  if (assetId) {
    where.assetId = assetId;
  }

  if (startDate && endDate) {
    where.eventTime = {
      [Op.between]: [new Date(startDate), new Date(endDate)],
    };
  } else if (startDate) {
    where.eventTime = { [Op.gte]: new Date(startDate) };
  } else if (endDate) {
    where.eventTime = { [Op.lte]: new Date(endDate) };
  }

  if (search) {
    where[Op.or] = [
      { title: { [Op.iLike]: `%${search}%` } },
      { description: { [Op.iLike]: `%${search}%` } },
      { assetName: { [Op.iLike]: `%${search}%` } },
    ];
  }

  // Calculate offset
  const offset = (parseInt(page) - 1) * parseInt(limit);

  try {
    // Get alerts with pagination (temporarily without asset join due to schema issues)
    console.log(`Fetching alerts: page=${page}, limit=${limit}, offset=${offset}, where=`, JSON.stringify(where));
    
    const { count, rows: alerts } = await models.Alert.findAndCountAll({
      where,
      limit: parseInt(limit),
      offset,
      order: [[sortBy, sortOrder.toUpperCase()]],
      // TODO: Re-enable when asset table schema is fixed
      // include: [
      //   {
      //     model: models.Asset,
      //     as: 'asset',
      //     attributes: ['id', 'name', 'assetType', 'ipAddress', 'criticality'],
      //   },
      // ],
    });

    console.log(`Alerts query result: count=${count}, alerts=${alerts.length}`);

    // Calculate pagination metadata
    const totalPages = Math.ceil(count / parseInt(limit));
    const hasNext = parseInt(page) < totalPages;
    const hasPrev = parseInt(page) > 1;

    const response = {
      alerts,
      pagination: {
        currentPage: parseInt(page),
        totalPages,
        totalItems: count,
        itemsPerPage: parseInt(limit),
        hasNext,
        hasPrev,
      },
    };

    console.log(`Alerts response: pagination=`, JSON.stringify(response.pagination));
    res.status(200).json(response);

  } catch (error) {
    console.error('Alerts query failed:', error);
    
    // Return empty response with error indication
    res.status(200).json({
      alerts: [],
      pagination: {
        currentPage: parseInt(page),
        totalPages: 1,
        totalItems: 0,
        itemsPerPage: parseInt(limit),
        hasNext: false,
        hasPrev: false,
      },
      error: 'Failed to fetch alerts',
    });
  }
});

/**
 * Get single alert by ID
 * GET /api/alerts/:id
 */
const getAlert = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  const alert = await models.Alert.findOne({
    where: { id, organizationId },
    include: [
      {
        model: models.Asset,
        as: 'asset',
        attributes: ['id', 'name', 'assetType', 'ipAddress', 'hostname', 'criticality', 'location', 'owner'],
      },
      {
        model: models.AlertMitreAnalysis,
        as: 'mitreAnalysisRecords',
        required: false,
      },
    ],
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  res.status(200).json({ alert });
});

/**
 * Create new alert
 * POST /api/alerts
 */
const createAlert = asyncHandler(async (req, res) => {
  const organizationId = req.user.organizationId;
  
  const alertData = {
    ...req.body,
    organizationId,
    // Explicitly handle isTestData parameter for test data consistency
    isTestData: req.body.isTestData === true || req.body.isTestData === 'true',
  };

  const alert = await models.Alert.create(alertData);

  // Create alert timeline event
  await models.AlertTimelineEvent.create({
    alertId: alert.id,
    timestamp: new Date(),
    type: 'alert_created',
    title: 'Alert Created',
    description: `Alert "${alert.title}" was created in the system`,
    userId: req.user?.id || null,
    userName: req.user?.firstName ? `${req.user.firstName} ${req.user.lastName}` : 'System',
    metadata: {
      severity: alert.severity,
      sourceSystem: alert.sourceSystem,
      assetName: alert.assetName,
    },
  });

  // Trigger automatic embedding generation (fire-and-forget)
  embeddingHelper.triggerEmbeddingForRecord('alert', alert.id, 'create');

  // Get the created alert with associations
  const createdAlert = await models.Alert.findByPk(alert.id, {
    include: [
      {
        model: models.Asset,
        as: 'asset',
        attributes: ['id', 'name', 'assetType', 'ipAddress', 'criticality'],
      },
    ],
  });

  // Create notification for the alert
  try {
    await notificationService.createFromAlert(createdAlert);
  } catch (error) {
    console.error('Failed to create notification for alert:', error);
    // Don't fail the request if notification creation fails
  }

  res.status(201).json({
    message: 'Alert created successfully',
    alert: createdAlert,
  });
});

/**
 * Update alert
 * PUT /api/alerts/:id
 */
const updateAlert = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  const oldStatus = alert.status;
  const updateData = { ...req.body };

  // If status is being updated, handle triage timestamp
  if (updateData.status && updateData.status !== oldStatus) {
    updateData.triageTimestamp = new Date();
    
    // If manual status change includes triage remarks, update them
    if (updateData.triageRemarks) {
      updateData.triageRemarks = {
        ...updateData.triageRemarks,
        updatedBy: req.user.username || req.user.id,
        updatedAt: new Date().toISOString(),
        previousStatus: oldStatus,
        manualUpdate: true
      };
    }
  }

  await alert.update(updateData);

  // Create timeline event for manual status changes
  if (updateData.status && updateData.status !== oldStatus) {
    await models.AlertTimelineEvent.create({
      alertId: alert.id,
      timestamp: new Date(),
      type: 'status_change',
      title: `Status Changed to ${updateData.status.replace('_', ' ').toUpperCase()}`,
      description: `Alert status manually changed from "${oldStatus}" to "${updateData.status}" by ${req.user.username || 'user'}${updateData.triageRemarks?.triageReason ? `. Reason: ${updateData.triageRemarks.triageReason}` : ''}`,
      userId: req.user.id,
      metadata: {
        originalStatus: oldStatus,
        newStatus: updateData.status,
        updatedBy: req.user.username || req.user.id,
        triageRemarks: updateData.triageRemarks,
        manualUpdate: true
      },
    });
  }

  // Trigger automatic embedding generation for updates (fire-and-forget)
  embeddingHelper.triggerEmbeddingForRecord('alert', alert.id, 'update');

  // Get updated alert with associations
  const updatedAlert = await models.Alert.findByPk(alert.id, {
    include: [
      {
        model: models.Asset,
        as: 'asset',
        attributes: ['id', 'name', 'assetType', 'ipAddress', 'criticality'],
      },
    ],
  });

  res.status(200).json({
    message: 'Alert updated successfully',
    alert: updatedAlert,
  });
});

/**
 * Delete alert
 * DELETE /api/alerts/:id
 */
const deleteAlert = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  await alert.destroy();

  res.status(200).json({
    message: 'Alert deleted successfully',
  });
});

/**
 * Bulk update alerts
 * PUT /api/alerts/bulk
 */
const bulkUpdateAlerts = asyncHandler(async (req, res) => {
  const { alertIds, updateData } = req.body;
  const organizationId = req.user.organizationId;

  if (!alertIds || !Array.isArray(alertIds) || alertIds.length === 0) {
    throw new ValidationError('Alert IDs are required');
  }

  if (!updateData || Object.keys(updateData).length === 0) {
    throw new ValidationError('Update data is required');
  }

  // Update alerts
  const [updatedCount] = await models.Alert.update(updateData, {
    where: {
      id: { [Op.in]: alertIds },
      organizationId,
    },
  });

  res.status(200).json({
    message: `${updatedCount} alerts updated successfully`,
    updatedCount,
  });
});

/**
 * Resolve alert with remarks
 * POST /api/alerts/:id/resolve
 */
const resolveAlert = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;
  const { 
    resolution = 'resolved', // 'resolved' or 'false_positive'
    remarks,
    reasoning
  } = req.body;

  // Validate resolution type
  if (!['resolved', 'false_positive'].includes(resolution)) {
    throw new ValidationError('Resolution must be "resolved" or "false_positive"');
  }

  // Validate remarks - required for manual resolutions
  if (!remarks || typeof remarks !== 'string' || remarks.trim().length === 0) {
    throw new ValidationError('Resolve remarks are required and must be a non-empty string');
  }

  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  // Check if alert is already resolved
  if (alert.status === 'resolved' || alert.status === 'false_positive') {
    throw new ValidationError('Alert is already resolved');
  }

  // Create resolve remarks data structure
  const resolveRemarksData = {
    resolvedBy: 'MANUAL_USER_RESOLUTION',
    resolvedAt: new Date().toISOString(),
    resolutionType: resolution,
    remarks: remarks.trim(),
    reasoning: reasoning ? reasoning.trim() : null,
    userId: req.user.id,
    userName: `${req.user.firstName} ${req.user.lastName}`,
    userEmail: req.user.email,
    autoResolved: false
  };

  // Update alert status and add resolve remarks
  await alert.update({
    status: resolution,
    resolveRemarks: resolveRemarksData,
    updatedAt: new Date(),
  });

  // Create timeline event for manual resolution
  try {
    await models.AlertTimelineEvent.create({
      alertId: alert.id,
      timestamp: new Date(),
      type: resolution === 'false_positive' ? 'user_action' : 'status_change',
      title: resolution === 'false_positive' ? 'Alert Marked as False Positive' : 'Alert Resolved',
      description: `Alert ${resolution === 'false_positive' ? 'marked as false positive' : 'resolved'} by ${req.user.firstName} ${req.user.lastName}. ${remarks}`,
      userId: req.user.id,
      userName: `${req.user.firstName} ${req.user.lastName}`,
      metadata: {
        resolutionType: resolution,
        originalStatus: alert.status,
        newStatus: resolution,
        remarks: remarks.trim(),
        reasoning: reasoning ? reasoning.trim() : null,
        resolvedBy: 'MANUAL_USER_RESOLUTION',
        autoResolved: false
      }
    });
  } catch (timelineError) {
    console.error('‚ùå Failed to create timeline event:', timelineError);
    // Don't throw the error - continue with response even if timeline fails
  }

  // Get updated alert with associations
  const updatedAlert = await models.Alert.findByPk(alert.id, {
    include: [
      {
        model: models.Asset,
        as: 'asset',
        attributes: ['id', 'name', 'assetType', 'ipAddress', 'criticality'],
      },
    ],
  });

  console.log(`‚úÖ Manual resolution: Alert ${alert.id} ${resolution} by ${req.user.firstName} ${req.user.lastName}`);

  res.status(200).json({
    message: `Alert ${resolution === 'false_positive' ? 'marked as false positive' : 'resolved'} successfully`,
    alert: updatedAlert,
    resolveRemarks: resolveRemarksData
  });
});

/**
 * Escalate alert to incident
 * POST /api/alerts/:id/escalate
 */
const escalateAlert = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;
  const { 
    title,
    description,
    severity,
    category,
    assignedTo 
  } = req.body;

  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  // Create incident from alert
  const incident = await models.Incident.create({
    title: title || `Incident: ${alert.title}`,
    description: description || alert.description,
    severity: severity || alert.severity,
    category: category || 'malware', // default category
    assignedTo,
    assignedToName: assignedTo ? 'System' : null, // Would need to lookup actual user name
    organizationId,
    alertIds: [alert.id],
    alertCount: 1,
    metadata: {
      sourceAlert: alert.id,
      escalatedBy: req.user.id,
      escalatedAt: new Date(),
    },
  });

  // Update alert status
  await alert.update({
    status: 'investigating',
  });

  // Create timeline event
  await models.TimelineEvent.create({
    timestamp: new Date(),
    type: 'action',
    title: 'Incident Created',
    description: `Alert escalated to incident by ${req.user.firstName} ${req.user.lastName}`,
    userId: req.user.id,
    userName: `${req.user.firstName} ${req.user.lastName}`,
    incidentId: incident.id,
  });

  res.status(201).json({
    message: 'Alert escalated to incident successfully',
    incident,
    alert,
  });
});

/**
 * Get alert statistics
 * GET /api/alerts/stats
 */
const getAlertStats = asyncHandler(async (req, res) => {
  const organizationId = req.user.organizationId;
  const { days = 7 } = req.query;
  
  const statistics = await alertStatsService.getAlertStatistics(organizationId, days);
  
  res.status(200).json(statistics);
});

/**
 * AI Analysis for alert
 * POST /api/alerts/:id/ai-analysis
 */
const analyzeAlert = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  // Find the alert
  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  try {
    const result = await alertAnalysisHelper.performAnalysis(alert, organizationId, req.user);
    res.status(200).json(result);
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message || 'AI analysis failed',
      processingTimeMs: Date.now() - Date.now(),
      timestamp: new Date().toISOString()
    });
  }
});

/**
 * AI Classification for alert - generates event type classification and contextual tags
 * POST /api/alerts/:id/ai-classification
 */
const aiClassification = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  // Find the alert
  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  try {
    const options = {
      refreshAnalysis: req.body.refreshAnalysis || false
    };

    const result = await alertClassificationHelper.performClassification(alert, organizationId, req.user, options);
    res.status(200).json(result);
  } catch (error) {
    const startTime = Date.now();
    res.status(500).json({
      success: false,
      error: error.message || 'AI classification failed',
      processingTimeMs: Date.now() - startTime,
      timestamp: new Date().toISOString()
    });
  }
});

/**
 * AI Generate Incident Form Data from Alert
 * POST /api/alerts/:id/ai-generate-incident-form
 * Uses Security Alert data AND existing AI Analysis as context
 */
const aiGenerateIncidentForm = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  // Find the alert with all available context
  const alert = await models.Alert.findOne({
    where: { id, organizationId },
    include: [
      {
        model: models.Asset,
        as: 'asset',
        attributes: ['id', 'name', 'assetType', 'ipAddress', 'criticality', 'location', 'owner'],
      },
    ],
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  try {
    const result = await incidentFormGenerationService.generateIncidentForm(alert, organizationId, req.user);
    res.status(200).json(result);
  } catch (error) {
    res.status(500).json({
      success: false,
      error: error.message || 'Incident form generation failed',
      timestamp: new Date().toISOString()
    });
  }
});

/**
    // Prepare comprehensive context from Security Alert AND existing AI Analysis
    const alertContext = {
      // Core alert data
      id: alert.id,
      title: alert.title,
      description: alert.description,
      severity: alert.severity,
      sourceSystem: alert.sourceSystem,
      eventTime: alert.eventTime,
      assetName: alert.assetName,
      assetId: alert.assetId,
      status: alert.status,
      assignedAgent: alert.assignedAgent,
      
      // Raw and enrichment data
      rawData: alert.rawData,
      enrichmentData: alert.enrichmentData,
      
      // Asset information
      asset: alert.asset,
      
      // Existing AI Analysis (if available)
      aiAnalysis: alert.aiAnalysis,
      aiAnalysisTimestamp: alert.aiAnalysisTimestamp
    };

    // Build comprehensive prompt using Security Alert + AI Analysis context
    const prompt = `As an expert SOC analyst, create an incident record from this Security Alert and any existing AI analysis. This is for incident escalation, not a blank incident.

SECURITY ALERT CONTEXT:
======================
Alert ID: ${alertContext.id}
Title: ${alertContext.title}
Description: ${alertContext.description}
Severity: ${alertContext.severity}/5 (${alertContext.severity >= 4 ? 'HIGH/CRITICAL' : alertContext.severity >= 3 ? 'MEDIUM' : 'LOW'})
Source System: ${alertContext.sourceSystem}
Event Time: ${alertContext.eventTime}
Affected Asset: ${alertContext.assetName} (${alertContext.assetId})
Asset Details: ${JSON.stringify(alertContext.asset)}
Current Status: ${alertContext.status}
Assigned Agent: ${alertContext.assignedAgent}

RAW EVENT DATA:
===============
${JSON.stringify(alertContext.rawData, null, 2)}

THREAT INTELLIGENCE:
===================
${JSON.stringify(alertContext.enrichmentData, null, 2)}

${alertContext.aiAnalysis ? `
EXISTING AI ANALYSIS:
====================
Previous Analysis: ${JSON.stringify(alertContext.aiAnalysis, null, 2)}
Analysis Date: ${alertContext.aiAnalysisTimestamp}
` : 'No existing AI analysis available.'}

TASK: Generate incident form data that escalates this security alert into a comprehensive incident record.

Generate incident creation form data in this exact JSON format:
{
  "title": "Comprehensive incident title based on alert and analysis",
  "description": "Detailed incident description that includes: alert summary, what was detected, affected systems, potential impact, current containment status, and investigation needs",
  "severity": 1-5 (maintain or adjust based on comprehensive analysis),
  "category": "malware|intrusion|data_breach|policy_violation|insider_threat",
  "responseplan": "Comprehensive incident response plan with: Immediate actions, Investigation steps, Containment measures, Communication plan, Recovery procedures",
  "impactAssessment": "Detailed business impact analysis including affected systems, data at risk, service disruption, and stakeholder impact",
  "recommendedActions": ["Specific, actionable immediate steps based on alert type and analysis"],
  "stakeholders": ["Specific people/teams to notify based on asset criticality and incident type"],
  "estimatedTimeline": "Realistic timeline for investigation, containment, and recovery",
  "investigationPlan": "COMPREHENSIVE investigation plan including: 1) Evidence collection (logs, memory dumps, network captures), 2) Digital forensics (file system analysis, registry examination, process analysis), 3) Network analysis (traffic patterns, communication endpoints, lateral movement), 4) Malware analysis (static/dynamic analysis, IOC extraction), 5) Timeline reconstruction, 6) Attribution analysis, 7) Scope determination (affected systems, data compromise), 8) Root cause analysis. Include specific tools, techniques, and methodologies for each phase.",
  "containmentStrategy": "DETAILED containment strategy with: 1) IMMEDIATE containment (network isolation, account disabling, process termination, service shutdown), 2) SHORT-TERM measures (patch deployment, access restrictions, monitoring enhancement), 3) LONG-TERM solutions (infrastructure hardening, policy updates, security controls enhancement), 4) Eradication steps (malware removal, artifact cleanup, IOC blocking), 5) Recovery procedures (system restoration, service resumption, data recovery), 6) Monitoring and validation (threat hunting, continuous monitoring, compliance verification). Specify tools, commands, and validation steps.",
  "confidence": 1-100
}

CRITICAL REQUIREMENTS:
1. Your response must be ONLY valid JSON - no markdown, no explanations, no code blocks
2. investigationPlan and containmentStrategy must be detailed (minimum 500 characters each)
3. Use proper line breaks (\\n) and formatting within the JSON strings
4. Include specific tools, techniques, and step-by-step procedures
5. Make it comprehensive enough for professional incident response

Focus on creating a comprehensive incident record that builds upon the alert data and any existing analysis. This should be ready for human review and approval.

RESPOND WITH ONLY THE JSON OBJECT - NO OTHER TEXT:`;

    // Generate AI suggestions
    const response = await aiGenerationService.generateResponse({
      prompt,
      organizationId
    });
    const analysis = response.content || response.response;
    const processingTime = Date.now() - startTime;

    // Parse AI response with enhanced error handling
    let aiSuggestions;
    try {
      // Log the raw AI response for debugging
      console.log('ü§ñ Raw AI Response Length:', typeof analysis === 'string' ? analysis.length : 'Not string');
      console.log('ü§ñ Raw AI Response Sample:', typeof analysis === 'string' ? analysis.substring(0, 200) + '...' : 'Not string');
      
      if (typeof analysis === 'string') {
        // Handle markdown code blocks and extract JSON
        let cleanedAnalysis = analysis.trim();
        
        // Remove markdown code block markers if present
        if (cleanedAnalysis.startsWith('```json')) {
          cleanedAnalysis = cleanedAnalysis.replace(/^```json\s*/, '').replace(/\s*```$/, '');
        } else if (cleanedAnalysis.startsWith('```')) {
          cleanedAnalysis = cleanedAnalysis.replace(/^```\s*/, '').replace(/\s*```$/, '');
        }
        
        // Try to extract and parse JSON from the cleaned response with multiple attempts
        let jsonMatch = cleanedAnalysis.match(/\{[\s\S]*\}/);
        let attempts = 0;
        let lastError = null;
        
        if (!jsonMatch) {
          throw new Error('No JSON structure found in AI response');
        }
        
        while (attempts < 3) {
          try {
            attempts++;
            let jsonString = jsonMatch[0];
            
            // Log what we're trying to parse
            console.log(`üîÑ JSON parse attempt ${attempts}, length: ${jsonString.length}`);
            console.log('üîç JSON preview:', jsonString.substring(0, 200) + (jsonString.length > 200 ? '...' : ''));
            
            // Clean up common JSON issues on retry attempts
            if (attempts > 1) {
              jsonString = jsonString
                .replace(/,(\s*[}\]])/g, '$1')     // Remove trailing commas
                .replace(/([^\\])\\([^"\\\/bfnrt])/g, '$1\\\\$2') // Fix invalid escape sequences
                .replace(/\n/g, '\\n')             // Escape newlines in strings
                .replace(/\r/g, '\\r')             // Escape carriage returns
                .replace(/\t/g, '\\t')             // Escape tabs
                .replace(/[\u0000-\u001f]/g, '');  // Remove control characters
              
              console.log('üßπ Applied JSON cleanup for attempt', attempts);
            }
            
            aiSuggestions = JSON.parse(jsonString);
            console.log('‚úÖ AI JSON parsing successful on attempt', attempts);
            console.log('üîç Parsed fields:', Object.keys(aiSuggestions));
            break;
            
          } catch (parseError) {
            lastError = parseError;
            console.warn(`‚ö†Ô∏è JSON parse attempt ${attempts} failed at position ${parseError.message.match(/position (\d+)/) ? parseError.message.match(/position (\d+)/)[1] : 'unknown'}: ${parseError.message}`);
            
            if (attempts === 1) {
              // On first failure, try to find a smaller, complete JSON block
              const smallerMatch = cleanedAnalysis.match(/\{(?:[^{}]|{[^{}]*})*\}/);
              if (smallerMatch && smallerMatch[0] !== jsonMatch[0]) {
                jsonMatch[0] = smallerMatch[0];
                console.log('üîÑ Trying smaller JSON block for attempt', attempts + 1);
                continue;
              }
            }
            
            if (attempts >= 3) {
              console.error('‚ùå All JSON parsing attempts failed. Raw response sample:');
              console.error(cleanedAnalysis.substring(2500, 2700)); // Show the area around position 2572
              throw new Error(`Failed to parse AI JSON after ${attempts} attempts. Last error: ${parseError.message}`);
            }
          }
        }
      } else {
        aiSuggestions = analysis;
      }
      
      // Validate that critical fields exist and are comprehensive
      if (aiSuggestions.investigationPlan && aiSuggestions.investigationPlan.length < 200) {
        console.warn('‚ö†Ô∏è AI Investigation Plan seems too short, may need prompt adjustment');
      }
      if (aiSuggestions.containmentStrategy && aiSuggestions.containmentStrategy.length < 200) {
        console.warn('‚ö†Ô∏è AI Containment Strategy seems too short, may need prompt adjustment');
      }
      
    } catch (parseError) {
      console.error('‚ùå Failed to parse AI response:', parseError);
      console.error('üîç AI Response Type:', typeof analysis);
      console.error('üîç AI Response Sample:', typeof analysis === 'string' ? analysis.substring(0, 500) : analysis);
      
      // Throw error instead of providing fallback
      throw new Error(`AI incident form generation failed - unable to parse response: ${parseError.message}`);
    }

    // Ensure all required fields with enhanced defaults
    const structuredSuggestions = {
      title: aiSuggestions.title || `Security Incident: ${alert.title}`,
      description: aiSuggestions.description || `Escalated from Security Alert: ${alert.description}`,
      severity: aiSuggestions.severity || alert.severity,
      category: aiSuggestions.category || (alert.severity >= 4 ? 'intrusion' : alert.severity >= 3 ? 'malware' : 'policy_violation'),
      responseplan: aiSuggestions.responseplan || 'Comprehensive incident response plan to be executed',
      impactAssessment: aiSuggestions.impactAssessment || `Impact assessment for ${alert.assetName} and related systems`,
      recommendedActions: aiSuggestions.recommendedActions || ['Investigate alert details', 'Assess system impact', 'Implement containment'],
      stakeholders: aiSuggestions.stakeholders || ['Security Team', 'IT Operations', 'Asset Owner'],
      estimatedTimeline: aiSuggestions.estimatedTimeline || '4-8 hours initial response',
      investigationPlan: aiSuggestions.investigationPlan || `INVESTIGATION PLAN:
1. Evidence collection from affected systems
2. Forensic analysis and malware examination  
3. Network traffic analysis and IOC identification
4. Timeline reconstruction and root cause analysis
5. Scope assessment and impact evaluation`,
      containmentStrategy: aiSuggestions.containmentStrategy || `CONTAINMENT STRATEGY:
1. Immediate isolation of affected systems
2. Account disabling and credential rotation
3. Malware removal and system sanitization
4. Network blocking of malicious indicators
5. Enhanced monitoring and threat hunting`,
      confidence: aiSuggestions.confidence || 80
    };

    // Log AI agent activity
    await aiAgentLogService.logAgentActivity({
      agentName: 'Alert and Incident Specialist Agent',
      taskName: 'create incident',
      description: `Create Incident from Alert: ${alert.title} - Generated comprehensive incident form with ${structuredSuggestions.confidence}% confidence`,
      inputTokens: response.inputTokens || 0,
      outputTokens: response.outputTokens || 0,
      executionTimeMs: processingTime,
      success: true,
      userId: req.user.id,
      organizationId,
      alertId: alert.id,
      aiProvider: response.aiProvider,
      aiModel: response.aiModel,
      metadata: {
        confidence: structuredSuggestions.confidence,
        category: structuredSuggestions.category,
        severity: structuredSuggestions.severity,
        hasExistingAnalysis: !!alert.aiAnalysis
      }
    });

    res.status(200).json({
      success: true,
      suggestions: structuredSuggestions,
      processingTime: processingTime,
      sourceAlert: {
        id: alert.id,
        title: alert.title,
        severity: alert.severity
      },
      hasExistingAnalysis: !!alert.aiAnalysis
    });

  } catch (error) {
    console.error('AI incident form generation failed:', error);
    
    const processingTime = Date.now() - startTime;
    
    // Log failed AI agent activity
    try {
      await aiAgentLogService.logAgentActivity({
        agentName: 'Alert and Incident Specialist Agent',
        taskName: 'create incident',
        description: `Failed to create incident from Alert: ${alert.title}`,
        executionTimeMs: processingTime,
        success: false,
        errorMessage: error.message || 'AI incident form generation failed',
        userId: req.user.id,
        organizationId,
        alertId: alert.id,
        metadata: {
          errorType: error.constructor.name,
          alertSeverity: alert.severity,
          hasExistingAnalysis: !!alert.aiAnalysis
        }
      });
    } catch (logError) {
      console.error('Failed to log AI agent activity:', logError);
    }
    
    res.status(200).json({
      success: false,
      error: 'AI incident form generation is not available. Please try again later.',
      processingTime: processingTime
    });
  }
});

/**
 * Helper function to proofread incident fields using tool-based approach
 */
async function proofreadIncidentFieldsWithTools({ fields, organizationId, userId }) {
  try {
    console.log('üîß Starting tool-based proofreading for', fields.length, 'fields');
    
    const toolExecutor = require('../tools/common/toolExecutor');
    const toolContext = { organizationId, userId, contextType: 'proofreading', sessionId: `proofreading_${Date.now()}` };
    const suggestions = {};
    const processedFields = [];
    
    // Process each field with appropriate proofreading tools
    for (const { fieldName, text } of fields) {
      try {
        console.log(`üîç Processing field: ${fieldName} (${text.length} chars)`);
        
        // Step 1: Analyze text quality
        const qualityAnalysis = await toolExecutor.executeTool(
          'analyze_text_quality',
          {
            fieldName,
            textContent: text,
            contentType: 'incident_report',
            analysisDepth: 'detailed'
          },
          toolContext
        );
        
        if (!qualityAnalysis.success || !qualityAnalysis.result.success || qualityAnalysis.result.analysis.isEmpty) {
          console.log(`‚è≠Ô∏è Skipping ${fieldName}: ${qualityAnalysis.result?.analysis?.isEmpty ? 'empty content' : 'analysis failed'}`);
          continue;
        }
        
        const analysis = qualityAnalysis.result.analysis;
        console.log(`üîç Analysis result for ${fieldName}:`, {
          overallScore: analysis.overallScore,
          priority: analysis.priority,
          hasIssues: analysis.issues?.length > 0,
          issueCount: analysis.issues?.length || 0
        });
        
        // Skip if text quality is already high, but provide explanation
        if (analysis.overallScore >= 85 && analysis.priority === 'low') {
          console.log(`‚ú® Field ${fieldName} already has high quality (${analysis.overallScore}), adding explanation`);
          
          processedFields.push({
            fieldName,
            hasImprovements: false,
            aiAnalysis: analysis,
            processingNote: `AI analysis complete: Text quality score ${analysis.overallScore}/100`,
            explanation: analysis.qualityExplanation || `This text received a high quality score of ${analysis.overallScore}/100. ${analysis.strengths?.join(' ') || 'The content demonstrates professional writing standards.'}`,
            aiProcessingConfirmed: analysis.aiProcessingNote || 'Processed by AI - not a timeout or fallback'
          });
          continue;
        }
        
        let improvedText = text;
        let hasImprovements = false;
        const improvements = [];
        
        // Step 2: Apply improvements based on analysis results
        
        // Grammar and spelling improvements
        const hasGrammarOrSpellingIssues = analysis.issues?.some(issue => 
          issue.type === 'grammar' || issue.type === 'spelling'
        );
        
        console.log(`üîç Grammar/spelling issues for ${fieldName}:`, hasGrammarOrSpellingIssues);
        if (hasGrammarOrSpellingIssues) {
          const grammarResult = await toolExecutor.executeTool(
            'improve_grammar_and_spelling',
            {
              fieldName,
              textContent: improvedText,
              preserveTechnicalTerms: true,
              preserveFormatting: true
            },
            toolContext
          );
          
          if (grammarResult.success && grammarResult.result.success && grammarResult.result.changes.length > 0) {
            improvedText = grammarResult.result.improvedText;
            hasImprovements = true;
            improvements.push(`Grammar/spelling: ${grammarResult.result.changes.length} fixes`);
          }
        }
        
        // Professional tone enhancement - check for tone, clarity, or completeness issues
        const hasToneIssues = analysis.issues?.some(issue => 
          issue.type === 'tone' || issue.type === 'clarity' || issue.type === 'completeness'
        ) || analysis.overallScore < 80;
        
        console.log(`üîç Tone issues for ${fieldName}:`, hasToneIssues);
        if (hasToneIssues) {
          const toneResult = await toolExecutor.executeTool(
            'enhance_professional_tone',
            {
              fieldName,
              textContent: improvedText,
              targetAudience: 'mixed',
              formalityLevel: 'professional',
              preserveUrgency: true
            },
            toolContext
          );
          
          if (toneResult.success && toneResult.result.success && toneResult.result.enhancements.length > 0) {
            improvedText = toneResult.result.enhancedText;
            hasImprovements = true;
            improvements.push(`Professional tone: ${toneResult.result.enhancements.length} enhancements`);
          }
        }
        
        // Technical terminology validation
        if (analysis.terminologyIssues?.length > 0) {
          const terminologyResult = await toolExecutor.executeTool(
            'validate_technical_terminology',
            {
              fieldName,
              textContent: improvedText,
              domainFocus: 'cybersecurity',
              standardsCompliance: true
            },
            toolContext
          );
          
          if (terminologyResult.success && terminologyResult.result.success && 
              terminologyResult.result.validationResults.corrections?.length > 0) {
            
            // Apply terminology corrections
            let correctedText = improvedText;
            for (const correction of terminologyResult.result.validationResults.corrections) {
              correctedText = correctedText.replace(
                new RegExp(`\\b${correction.original}\\b`, 'gi'), 
                correction.corrected
              );
            }
            
            if (correctedText !== improvedText) {
              improvedText = correctedText;
              hasImprovements = true;
              improvements.push(`Terminology: ${terminologyResult.result.validationResults.corrections.length} corrections`);
            }
          }
        }
        
        // Clarity and conciseness improvements
        if (analysis.readabilityScore < 75) {
          const clarityResult = await toolExecutor.executeTool(
            'ensure_clarity_and_conciseness',
            {
              fieldName,
              textContent: improvedText,
              maxReduction: 0.15,
              maintainDetail: true,
              improveReadability: true
            },
            toolContext
          );
          
          if (clarityResult.success && clarityResult.result.success && 
              clarityResult.result.improvements.length > 0) {
            improvedText = clarityResult.result.improvedText;
            hasImprovements = true;
            improvements.push(`Clarity: ${clarityResult.result.improvements.length} improvements`);
          }
        }
        
        // Add to suggestions if we made any improvements
        if (hasImprovements && improvedText !== text) {
          suggestions[fieldName] = improvedText;
          processedFields.push({
            fieldName,
            originalLength: text.length,
            improvedLength: improvedText.length,
            improvements: improvements.join(', '),
            qualityScore: analysis.overallScore
          });
          
          console.log(`‚úÖ Improved ${fieldName}: ${improvements.join(', ')}`);
        } else {
          console.log(`üìù No improvements needed for ${fieldName} (score: ${analysis.overallScore})`);
        }
        
      } catch (fieldError) {
        console.error(`‚ùå Error processing field ${fieldName}:`, fieldError);
        console.error(`‚ùå Field processing error details:`, {
          fieldName,
          textLength: text?.length,
          errorMessage: fieldError.message,
          errorName: fieldError.name,
          errorCode: fieldError.code,
          stack: fieldError.stack?.split('\n')[0] // First line of stack trace
        });
        
        // Add failed field to processed fields for debugging
        processedFields.push({
          fieldName,
          hasImprovements: false,
          processingNote: `Failed to process: ${fieldError.message}`,
          explanation: 'Field processing failed due to an error',
          aiProcessingConfirmed: 'Error occurred during processing',
          error: fieldError.message
        });
        // Continue with other fields
      }
    }
    
    // Step 3: Validate consistency across all improved fields if we have multiple
    if (Object.keys(suggestions).length > 1) {
      try {
        const consistencyResult = await toolExecutor.executeTool(
          'validate_consistency',
          {
            fieldsData: suggestions,
            checkTerminology: true,
            checkFormatting: true,
            checkTone: true
          },
          toolContext
        );
        
        if (consistencyResult.success && consistencyResult.result.success && 
            consistencyResult.result.consistencyResults.issues.length > 0) {
          console.log(`‚ö†Ô∏è Found ${consistencyResult.result.consistencyResults.issues.length} consistency issues across fields`);
          
          // Apply consistency fixes would go here in a more advanced implementation
          // For now, we'll just log the issues
        }
      } catch (consistencyError) {
        console.error('‚ùå Error validating consistency:', consistencyError);
        // Don't fail the entire operation for consistency issues
      }
    }
    
    console.log(`üéØ Tool-based proofreading completed: ${Object.keys(suggestions).length}/${fields.length} fields improved`);
    console.log('üìä Processing summary:', processedFields);
    
    return {
      suggestions,
      processedFields,
      totalProcessed: fields.length,
      fieldsImproved: Object.keys(suggestions).length,
      processingComplete: true
    };
    
  } catch (error) {
    console.error('‚ùå Tool-based proofreading failed:', error);
    console.error('‚ùå Error details:', {
      message: error.message,
      stack: error.stack,
      code: error.code,
      name: error.name,
      fieldsCount: fields?.length,
      organizationId,
      userId
    });
    throw error;
  }
}

/**
 * AI Proof Read Incident Form Fields
 * POST /api/alerts/proof-read
 * Uses AI to improve grammar and spelling in text fields
 */
const proofReadIncidentFields = asyncHandler(async (req, res) => {
  const { fields } = req.body;
  const startTime = Date.now();

  if (!fields || typeof fields !== 'object' || Object.keys(fields).length === 0) {
    throw new ValidationError('Fields object is required for proofreading');
  }

  try {
    const fieldsToProofRead = Object.entries(fields)
      .filter(([_, value]) => value && typeof value === 'string' && value.trim().length > 0)
      .map(([fieldName, text]) => ({ fieldName, text: text.trim() }));

    if (fieldsToProofRead.length === 0) {
      return res.status(200).json({
        success: true,
        suggestions: {},
        processingTime: Date.now() - startTime,
        message: 'No text fields provided for proofreading'
      });
    }

    // Use tool-based approach for proofreading
    console.log('üõ†Ô∏è Using tool-based proofreading approach for', fieldsToProofRead.length, 'fields');
    
    const result = await proofreadIncidentFieldsWithTools({
      fields: fieldsToProofRead,
      organizationId: req.user.organizationId,
      userId: req.user.id
    });

    const processingTime = Date.now() - startTime;

    // Log AI agent activity
    await aiAgentLogService.logAgentActivity({
      agentName: 'Alert and Incident Specialist Agent',
      taskName: 'proof read (tool-based)',
      description: `Tool-based proof reading - Processed ${result.totalProcessed} fields, found ${result.fieldsImproved} improvements`,
      executionTimeMs: processingTime,
      success: true,
      userId: req.user.id,
      organizationId: req.user.organizationId,
      metadata: {
        approach: 'tool_based',
        fieldsProcessed: result.totalProcessed,
        improvementsFound: result.fieldsImproved,
        fieldsNames: fieldsToProofRead.map(f => f.fieldName),
        processedFields: result.processedFields
      }
    });

    res.status(200).json({
      success: true,
      suggestions: result.suggestions,
      processingTime,
      fieldsProcessed: result.totalProcessed,
      improvementsFound: result.fieldsImproved,
      approach: 'tool_based',
      aiProcessingComplete: result.processingComplete,
      processedFields: result.processedFields,
      detailedResults: result.processedFields.map(field => ({
        fieldName: field.fieldName,
        hasImprovements: field.hasImprovements,
        processingNote: field.processingNote,
        explanation: field.explanation,
        aiProcessingConfirmed: field.aiProcessingConfirmed,
        qualityScore: field.aiAnalysis?.overallScore,
        strengths: field.aiAnalysis?.strengths || []
      })),
      message: result.fieldsImproved > 0 
        ? `AI analysis complete: ${result.fieldsImproved} of ${result.totalProcessed} fields improved`
        : `AI analysis complete: All ${result.totalProcessed} fields already meet high quality standards`
    });

  } catch (error) {
    console.error('Tool-based proofreading failed:', error);
    
    const processingTime = Date.now() - startTime;
    
    // Log failed AI agent activity
    try {
      await aiAgentLogService.logAgentActivity({
        agentName: 'Alert and Incident Specialist Agent',
        taskName: 'proof read (tool-based)',
        description: `Failed to proof read incident form fields using tool-based approach`,
        executionTimeMs: processingTime,
        success: false,
        errorMessage: error.message || 'Tool-based proofreading failed',
        userId: req.user.id,
        organizationId: req.user.organizationId,
        metadata: {
          approach: 'tool_based',
          errorType: error.constructor.name,
          fieldsAttempted: fieldsToProofRead?.length || 0
        }
      });
    } catch (logError) {
      console.error('Failed to log AI agent activity:', logError);
    }
    
    // Enhanced error classification
    const isTimeoutError = error.message?.includes('timeout') || error.code === 'ECONNABORTED' || processingTime > 300000;
    const isAIProviderError = error.message?.includes('AI') || error.message?.includes('Ollama') || error.message?.includes('provider');
    const isNetworkError = error.code === 'ECONNREFUSED' || error.code === 'ENOTFOUND' || error.message?.includes('connect');
    const isToolExecutorError = error.message?.includes('tool') || error.message?.includes('executor');
    const isConfigError = error.message?.includes('config') || error.message?.includes('provider config');
    
    let userMessage = 'AI proofreading service is not available. Please try again later.';
    let errorDetails = `Error: ${error.message || 'Unknown error occurred during AI processing.'}`;
    
    if (isTimeoutError) {
      userMessage = 'AI processing is taking longer than expected. The analysis may still be in progress.';
      errorDetails = `AI analysis timeout after ${Math.round(processingTime/1000)} seconds. The AI model (gpt-oss:20b) is processing your text but requires more time than the 5-minute limit.`;
    } else if (isNetworkError) {
      userMessage = 'Cannot connect to AI service. Please check if the AI service is running.';
      errorDetails = `Network error: ${error.message}. The AI service (Ollama/gpt-oss:20b) may not be started or accessible.`;
    } else if (isToolExecutorError) {
      userMessage = 'AI tool execution failed. Please check the AI tool configuration.';
      errorDetails = `Tool executor error: ${error.message}. The proofreading tools may not be properly configured.`;
    } else if (isConfigError) {
      userMessage = 'AI service configuration error. Please check AI provider settings.';
      errorDetails = `Configuration error: ${error.message}. The AI provider configuration may be incomplete or invalid.`;
    } else if (isAIProviderError) {
      userMessage = 'AI analysis service is temporarily unavailable.';
      errorDetails = `AI provider error: ${error.message}. This is not a timeout or fallback response.`;
    }

    res.status(200).json({
      success: false,
      error: userMessage,
      errorDetails: errorDetails,
      processingTime,
      suggestions: {},
      approach: 'tool_based',
      isTimeout: isTimeoutError,
      isNetworkError: isNetworkError,
      isToolExecutorError: isToolExecutorError,
      isConfigError: isConfigError,
      isAIProviderError: isAIProviderError,
      technicalError: error.message,
      errorType: error.name || error.constructor.name,
      errorCode: error.code,
      fieldsAttempted: fieldsToProofRead?.length || 0,
      helpMessage: isTimeoutError 
        ? 'The AI is analyzing your text. Large text or complex analysis may take 2-5 minutes. You can try again or wait for processing to complete.'
        : isNetworkError
        ? 'Please check if the AI service (Ollama with gpt-oss:20b model) is running and accessible.'
        : isToolExecutorError
        ? 'The proofreading tools encountered an execution error. Please check the tool configuration and AI service status.'
        : 'This is a genuine AI processing error, not a timeout or fallback response. The AI attempted to analyze your text but encountered an issue.'
    });
  }
});

/**
 * Get incidents created from this alert (reverse lookup)
 * GET /api/alerts/:id/incidents
 */
const getAlertIncidents = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  // First verify the alert exists and belongs to the organization
  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  try {
    // Find incidents that contain this alert ID in their alertIds array
    const incidents = await models.Incident.findAll({
      where: {
        organizationId,
        alertIds: {
          [Op.contains]: [id] // PostgreSQL array contains operator
        }
      },
      include: [
        {
          model: models.User,
          as: 'assignedUser',
          attributes: ['id', 'username', 'firstName', 'lastName', 'email'],
          required: false,
        },
        {
          model: models.TimelineEvent,
          as: 'timeline',
          limit: 3, // Just show recent timeline events
          order: [['timestamp', 'DESC']],
          required: false,
        },
      ],
      order: [['createdAt', 'DESC']] // Most recent incidents first
    });

    res.status(200).json({
      success: true,
      incidents,
      count: incidents.length,
      alert: {
        id: alert.id,
        title: alert.title,
        severity: alert.severity,
        status: alert.status
      }
    });

  } catch (error) {
    console.error('Failed to fetch alert incidents:', error);
    
    res.status(200).json({
      success: false,
      incidents: [],
      count: 0,
      error: 'Failed to fetch related incidents'
    });
  }
});

/**
 * Get alert timeline events
 * GET /api/alerts/:id/timeline
 */
const getAlertTimeline = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  // Verify alert exists and belongs to organization
  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  // Get timeline events for this alert
  const timelineEvents = await models.AlertTimelineEvent.findAll({
    where: { alertId: id },
    include: [
      {
        model: models.User,
        as: 'user',
        attributes: ['id', 'firstName', 'lastName', 'email'],
        required: false,
      },
    ],
    order: [['timestamp', 'DESC']],
  });

  res.status(200).json({
    success: true,
    timeline: timelineEvents,
    count: timelineEvents.length,
    alert: {
      id: alert.id,
      title: alert.title,
      severity: alert.severity,
      status: alert.status
    }
  });
});

/**
 * Update incident confirmation details for an alert
 * PUT /api/alerts/:id/incident-confirmation
 */
const updateIncidentConfirmation = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;
  const { confirmationDetails } = req.body;

  // Verify alert exists and belongs to organization
  const alert = await models.Alert.findOne({
    where: { id, organizationId },
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  // Validate confirmation details structure
  if (!confirmationDetails || typeof confirmationDetails !== 'object') {
    throw new BadRequestError('Valid confirmationDetails object is required');
  }

  // Update the alert with incident confirmation details
  await alert.update({
    incidentConfirmationDetails: {
      ...alert.incidentConfirmationDetails || {},
      ...confirmationDetails,
      updatedAt: new Date(),
      updatedBy: req.user.id,
      updatedByName: req.user.username || req.user.name
    }
  });

  // Create timeline event for confirmation update
  await models.AlertTimelineEvent.create({
    timestamp: new Date(),
    type: 'user_action',
    title: 'Incident Confirmation Updated',
    description: 'SOC manager updated incident verification and confirmation details',
    userId: req.user.id,
    userName: req.user.username || req.user.name,
    alertId: id,
    metadata: {
      action: 'update_incident_confirmation',
      previousConfirmation: alert.incidentConfirmationDetails,
      newConfirmation: confirmationDetails
    },
    isTestData: alert.isTestData || false
  });

  res.status(200).json({
    success: true,
    message: 'Incident confirmation details updated successfully',
    alert: {
      id: alert.id,
      title: alert.title,
      incidentConfirmationDetails: alert.incidentConfirmationDetails
    }
  });
});

/**
 * Helper function to create alert without HTTP context
 * Used by other controllers like test-data.controller
 */
const createAlertHelper = async (alertData, user) => {
  const organizationId = user.organizationId;
  
  const finalAlertData = {
    ...alertData,
    organizationId,
    // Explicitly handle isTestData parameter for test data consistency
    isTestData: alertData.isTestData === true || alertData.isTestData === 'true',
  };

  const alert = await models.Alert.create(finalAlertData);

  // Create alert timeline event
  await models.AlertTimelineEvent.create({
    alertId: alert.id,
    timestamp: new Date(),
    type: 'alert_created',
    title: 'Alert Created',
    description: `Alert "${alert.title}" was created in the system`,
    userId: user?.id || null,
    userName: user?.firstName ? `${user.firstName} ${user.lastName}` : 'System',
    metadata: {
      severity: alert.severity,
      sourceSystem: alert.sourceSystem,
      assetName: alert.assetName,
    },
  });

  // Trigger automatic embedding generation (fire-and-forget)
  embeddingHelper.triggerEmbeddingForRecord('alert', alert.id, 'create');

  // Get the created alert with associations
  const createdAlert = await models.Alert.findByPk(alert.id, {
    include: [
      {
        model: models.Asset,
        as: 'asset',
        attributes: ['id', 'name', 'assetType', 'ipAddress', 'criticality'],
      },
    ],
  });

  // Create notification for the alert
  try {
    const notificationService = require('../services/notificationService');
    await notificationService.createFromAlert(createdAlert);
  } catch (error) {
    console.error('Failed to create notification for alert:', error);
    // Don't fail the request if notification creation fails
  }

  return createdAlert;
};

/**
 * Get incident confirmation details for an alert
 * GET /api/alerts/:id/incident-confirmation
 */
const getIncidentConfirmation = asyncHandler(async (req, res) => {
  const { id } = req.params;
  const organizationId = req.user.organizationId;

  // Verify alert exists and belongs to organization
  const alert = await models.Alert.findOne({
    where: { id, organizationId },
    attributes: ['id', 'title', 'severity', 'status', 'incidentConfirmationDetails', 'aiAnalysis']
  });

  if (!alert) {
    throw new NotFoundError('Alert not found');
  }

  res.status(200).json({
    success: true,
    alert: {
      id: alert.id,
      title: alert.title,
      severity: alert.severity,
      status: alert.status,
      incidentConfirmationDetails: alert.incidentConfirmationDetails || null,
      aiAnalysis: alert.aiAnalysis || null
    }
  });
});

module.exports = {
  getAlerts,
  getAlert,
  createAlert,
  createAlertHelper,
  updateAlert,
  deleteAlert,
  bulkUpdateAlerts,
  resolveAlert,
  escalateAlert,
  getAlertStats,
  analyzeAlert,
  aiClassification,
  aiGenerateIncidentForm,
  proofReadIncidentFields,
  getAlertIncidents,
  getAlertTimeline,
  updateIncidentConfirmation,
  getIncidentConfirmation,
};